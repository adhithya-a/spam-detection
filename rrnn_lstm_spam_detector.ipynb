{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import SimpleRNN, LSTM, GRU, Embedding, Dense, Flatten\n",
    "from keras.models import Sequential\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras_preprocessing.sequence import pad_sequences\n",
    "from keras.callbacks import TensorBoard\n",
    "from keras.utils import plot_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def main(rnn_model):\n",
    "    def message_to_array(msg):\n",
    "        msg = msg.lower().split(' ')\n",
    "        test_seq = np.array([word_index[word] for word in msg])\n",
    "\n",
    "        test_seq = np.pad(test_seq, (500-len(test_seq), 0), 'constant', constant_values=(0))\n",
    "        test_seq = test_seq.reshape(1, 500)\n",
    "        return test_seq\n",
    "\n",
    "    df = pd.read_csv(\"spam.csv\", encoding=\"ISO-8859-1\",usecols=['v1', 'v2'])\n",
    "    df.rename(columns = {'v1':'label', 'v2':'text'}, inplace=True)\n",
    "    df.head()\n",
    "    df.info()\n",
    "    df.shape\n",
    "    \n",
    "\n",
    "    print('The number of ham messages in the dataset is {}'.format(df['label'].value_counts()[0]))\n",
    "    print('The number of spam messages in the dataset is {}'.format(df['label'].value_counts()[1]))      \n",
    "\n",
    "    messages = []\n",
    "    labels = []\n",
    "    for index, row in df.iterrows():\n",
    "        messages.append(row['text'])\n",
    "        if row['label'] == 'ham':\n",
    "            labels.append(0)\n",
    "        else:\n",
    "            labels.append(1)\n",
    "\n",
    "    messages = np.asarray(messages)\n",
    "    labels = np.asarray(labels)\n",
    "\n",
    "    print(\"Number of messages: \", len(messages))\n",
    "    print(\"Number of labels: \", len(labels))\n",
    "\n",
    "    max_vocab = 10000\n",
    "    max_len = 500\n",
    "\n",
    "    # Ignore all words except the 10000 most common words\n",
    "    tokenizer = Tokenizer(num_words=max_vocab)\n",
    "    # Calculate the frequency of words\n",
    "    tokenizer.fit_on_texts(messages)\n",
    "    # Convert array of messages to list of sequences of integers\n",
    "    sequences = tokenizer.texts_to_sequences(messages)\n",
    "\n",
    "    # Dict keeping track of words to integer index\n",
    "    word_index = tokenizer.word_index\n",
    "\n",
    "    # Convert the array of sequences(of integers) to 2D array with padding\n",
    "    # maxlen specifies the maximum length of sequence (truncated if longer, padded if shorter)\n",
    "    df = pad_sequences(sequences, maxlen=max_len)\n",
    "\n",
    "    print(\"data shape: \", df.shape)\n",
    "\n",
    "    # We will use 70% of data for training & validation(70% train, 30% validation) and 30% for testing\n",
    "    train_samples = int(len(messages)*0.7)\n",
    "\n",
    "    messages_train = df[:train_samples]\n",
    "    labels_train = labels[:train_samples]\n",
    "\n",
    "    messages_test = df[train_samples:len(messages)-2]\n",
    "    labels_test = labels[train_samples:len(messages)-2]\n",
    "\n",
    "    embedding_mat_columns=50\n",
    "    # Construct the SimpleRNN model\n",
    "    model = Sequential()\n",
    "    ## Add embedding layer to convert integer encoding to word embeddings(the model learns the\n",
    "    ## embedding matrix during training), embedding matrix has max_vocab as no. of rows and chosen\n",
    "    ## no. of columns\n",
    "    model.add(Embedding(input_dim=max_vocab, output_dim=embedding_mat_columns, input_length=max_len))\n",
    "\n",
    "    if rnn_model == 'SimpleRNN':\n",
    "        model.add(SimpleRNN(units=embedding_mat_columns))\n",
    "    elif rnn_model == 'LSTM':\n",
    "        model.add(LSTM(units=embedding_mat_columns))\n",
    "    # else:\n",
    "    #     model.add(GRU(units=embedding_mat_columns))\n",
    "\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop', loss='binary_crossentropy', metrics=['acc'])\n",
    "    model.summary()\n",
    "\n",
    "    #plot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "    # Training the model\n",
    "    model.fit(messages_train, labels_train, epochs=8, batch_size=500, validation_split=0.3)\n",
    "\n",
    "    # Testing the model\n",
    "    predict_x=model.predict(messages_test) \n",
    "    classes_x=np.argmax(predict_x,axis=1)\n",
    "    acc = model.evaluate(messages_test, labels_test)\n",
    "    print(\"Test loss is {0:.2f}, Accuracy is {1:.2f}  \".format(acc[0],acc[1]))\n",
    "\n",
    "    # Constructing a custom message to check model\n",
    "    custom_msg = 'Congratulations ur awarded 500 of CD vouchers or 125gift guaranteed Free entry for movies'\n",
    "    test_seq = message_to_array(custom_msg)\n",
    "    #pred = model.predict_classes(test_seq)\n",
    "    predict_x=model.predict(test_seq) \n",
    "    classes_x=np.argmax(predict_x,axis=1)\n",
    "    print(classes_x)\n",
    "\n",
    "    sms_test = ['Hi Paul, would you come around tonight']\n",
    "    print(\"Test sms 1: \",sms_test)\n",
    "    sms_seq = tokenizer.texts_to_sequences(sms_test)\n",
    "\n",
    "    sms_pad = pad_sequences(sms_seq, maxlen=max_len, padding='post')\n",
    "    tokenizer.index_word\n",
    "    sms_pad\n",
    "    predict_1=model.predict(sms_pad) \n",
    "    classes_1=np.argmax(predict_1,axis=1)\n",
    "    if(classes_1==[0]):\n",
    "        print(\"Ham\")\n",
    "    else:\n",
    "        print(\"Spam\")\n",
    "\n",
    "    sms_test = ['Free SMS service for anyone']\n",
    "    print(\"Test sms 2: \",sms_test)\n",
    "    sms_seq = tokenizer.texts_to_sequences(sms_test)\n",
    "\n",
    "    sms_pad = pad_sequences(sms_seq, maxlen=max_len, padding='post')\n",
    "    tokenizer.index_word\n",
    "    sms_pad\n",
    "    predict_2=model.predict(sms_pad) \n",
    "    classes_2=np.argmax(predict_2,axis=1)\n",
    "    if(classes_2==[0]):\n",
    "        print(\"Ham\")\n",
    "    else:\n",
    "        print(\"Spam\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5572 entries, 0 to 5571\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   5572 non-null   object\n",
      " 1   text    5572 non-null   object\n",
      "dtypes: object(2)\n",
      "memory usage: 87.2+ KB\n",
      "The number of ham messages in the dataset is 4825\n",
      "The number of spam messages in the dataset is 747\n",
      "Number of messages:  5572\n",
      "Number of labels:  5572\n",
      "data shape:  (5572, 500)\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding_1 (Embedding)     (None, 500, 50)           500000    \n",
      "                                                                 \n",
      " simple_rnn_1 (SimpleRNN)    (None, 50)                5050      \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 51        \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 505,101\n",
      "Trainable params: 505,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/8\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.5875 - acc: 0.7154 - val_loss: 0.3791 - val_acc: 0.8778\n",
      "Epoch 2/8\n",
      "6/6 [==============================] - 6s 999ms/step - loss: 0.3529 - acc: 0.8729 - val_loss: 0.3221 - val_acc: 0.8718\n",
      "Epoch 3/8\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3451 - acc: 0.8663 - val_loss: 0.3573 - val_acc: 0.8778\n",
      "Epoch 4/8\n",
      "6/6 [==============================] - 7s 1s/step - loss: 0.3687 - acc: 0.8623 - val_loss: 0.3510 - val_acc: 0.8778\n",
      "Epoch 5/8\n",
      "6/6 [==============================] - 8s 1s/step - loss: 0.3549 - acc: 0.8623 - val_loss: 0.3426 - val_acc: 0.8778\n",
      "Epoch 6/8\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3371 - acc: 0.8623 - val_loss: 0.3298 - val_acc: 0.8778\n",
      "Epoch 7/8\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.3084 - acc: 0.8623 - val_loss: 0.3046 - val_acc: 0.8778\n",
      "Epoch 8/8\n",
      "6/6 [==============================] - 6s 1s/step - loss: 0.2493 - acc: 0.8861 - val_loss: 0.2238 - val_acc: 0.9308\n",
      "53/53 [==============================] - 1s 25ms/step\n",
      "53/53 [==============================] - 1s 25ms/step - loss: 0.2304 - acc: 0.9251\n",
      "Test loss is 0.23, Accuracy is 0.93  \n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "[0]\n",
      "Test sms 1:  ['Hi Paul, would you come around tonight']\n",
      "1/1 [==============================] - 0s 40ms/step\n",
      "Ham\n",
      "Test sms 2:  ['Free SMS service for anyone']\n",
      "1/1 [==============================] - 0s 32ms/step\n",
      "Ham\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    main('SimpleRNN')\n",
    "    #main('LSTM')\n",
    "   # main('GRU')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.8 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7d0a37138ffd9c2a5f5132427dd3a113582efc397067d69de3686026f03bbd13"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
